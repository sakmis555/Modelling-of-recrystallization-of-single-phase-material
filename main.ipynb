{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import random\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euler_angles_fn():\n",
    "  arr = np.array( [[0, 0, 0], [0, 0, 90], [0, 22, 0], [0, 22, 90], [53, 36, 60]])\n",
    "  index = np.random.randint(0,5)\n",
    "  index\n",
    "  return arr[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def theta_finder():\n",
    "  arr = np.array( [0.01, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.64])\n",
    "  theta = []\n",
    "  theta_m = 15\n",
    "   \n",
    "  for i in range(arr.size):\n",
    "    temp = (-5 * np.log( 1 - arr[i]))\n",
    "    theta_c = theta_m * np.power( temp, (1/4))\n",
    "    theta.append(theta_c)\n",
    "  return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gamma(theta):\n",
    "  ans = []\n",
    "  gamma_nod = 1\n",
    "  theta_m = 15\n",
    "  for i in range(len(theta)):\n",
    "    temp = gamma_nod * (theta[i]/theta_m) * (1 - np.log(theta[i]/theta))\n",
    "    ans.append(ans)\n",
    "  return ans\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def theta_calculator( x,y):\n",
    "  \n",
    "  A = np.cos(x[0] - y[0]) * np.cos(x[1] - y[1])* ( 1 + np.cos(x[2])*np.cos(y[2])) - np.sin(x[0] - y[0])* np.sin(x[1] - y[1])* (np.cos(x[2]) + np.cos(y[2])) + (np.cos(x[0] - y[0]) + np.cos(x[1] - y[1]))* np.sin( x[2]) * np.sin(y[2]) + ( np.cos(x[2]) * np.cos(y[2]) )\n",
    "  theta = np.arccos((A-1)/2)\n",
    "  ans = np.degrees(theta)\n",
    "  return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotation_point_groups():\n",
    "  mat = [ [[1,0,0],[0,1,0],[0,0,1]], [[0,0,-1],[0,-1,0],[-1,0,0]], [[0,0,1],[1,0,0],[0,1,0]], [[0,1,0],[0,0,1],[1,0,0]], [[0,-1,0],[-1,0,0],[0,0,-1]], [[-1,0,0],[0,0,-1],[0,-1,0]] ] \n",
    "  dup = copy.deepcopy(mat)\n",
    "\n",
    "  for i in range(len(mat)):\n",
    "\n",
    "    for j in range(0,2):\n",
    "      for k in range(1,3):\n",
    "        if j != k:\n",
    "          \n",
    "          temp = copy.deepcopy(mat[i])\n",
    "          for l in range( 0,3):\n",
    "            \n",
    "            temp[j][l] = temp[j][l] * -1\n",
    "            temp[k][l] = temp[k][l] * -1\n",
    "          dup.append(temp)\n",
    "  \n",
    "  return dup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_point_x():\n",
    "\n",
    "  x_0 = np.random.randint(0, 149)\n",
    "  return x_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_point_y():\n",
    "\n",
    "  y_0 = np.random.randint(0, 150)\n",
    "  return y_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neighbours_of_point(x,y):\n",
    "\n",
    "  array = np.empty((4,2))\n",
    "  if( x == 149):\n",
    "    x1 = (((x + 1) % 149) - 1)\n",
    "  else:\n",
    "    x1 = x + 1\n",
    "\n",
    "  if( x == 0 ):\n",
    "    x2 = (((x - 1 + 149) % 149) + 1)\n",
    "  else:\n",
    "    x2 = x - 1\n",
    "  \n",
    "  if( y == 150):\n",
    "    y1 = (((y + 1) % 150) - 1)\n",
    "  else:\n",
    "    y1 = y + 1\n",
    "\n",
    "  if( y == 0):\n",
    "    y2 = (((y - 1 + 150 ) % 150) + 1)\n",
    "  else:\n",
    "    y2 = y - 1\n",
    "      \n",
    "  array[0][0] = x1\n",
    "  array[0][1] = y\n",
    "  array[1][0] = x2\n",
    "  array[1][1] = y\n",
    "  array[2][0] = x\n",
    "  array[2][1] = y1\n",
    "  array[3][0] = x\n",
    "  array[3][1] = y2\n",
    "  return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def current_euler_angle(required_data, x, y):\n",
    "  euler_angle_mat = np.empty((len(required_data),5))\n",
    "\n",
    "  # Store the euler angles in euler_angle_mat\n",
    "  for ind in required_data.index:\n",
    "    euler_angle_mat[ind][0] = required_data['Phi_1'][ind]\n",
    "    euler_angle_mat[ind][1] = required_data['Phi'][ind]\n",
    "    euler_angle_mat[ind][2] = required_data['Phi_2'][ind]\n",
    "    euler_angle_mat[ind][3] = required_data['X'][ind]\n",
    "    euler_angle_mat[ind][4] = required_data['Y'][ind]\n",
    "  \n",
    "  for ind in range(len(euler_angle_mat)):\n",
    "    if( euler_angle_mat[ind][3] == x and euler_angle_mat[ind][4] == y):\n",
    "      res_array = np.array([euler_angle_mat[ind][0], euler_angle_mat[ind][1], euler_angle_mat[ind][2]])\n",
    "      return res_array\n",
    "  return [0,0,0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HashTable:\n",
    " \n",
    "    # Create empty bucket list of given size\n",
    "    def __init__(self, size):\n",
    "        self.size = size\n",
    "        self.hash_table = self.create_buckets()\n",
    " \n",
    "    def create_buckets(self):\n",
    "        return [[] for _ in range(self.size)]\n",
    " \n",
    "    # Insert values into hash map\n",
    "    def set_val(self, key, val):\n",
    "       \n",
    "        # Get the index from the key\n",
    "        # using hash function\n",
    "        hashed_key = hash(key) % self.size\n",
    "         \n",
    "        # Get the bucket corresponding to index\n",
    "        bucket = self.hash_table[hashed_key]\n",
    " \n",
    "        found_key = False\n",
    "        for index, record in enumerate(bucket):\n",
    "            record_key, record_val = record\n",
    "             \n",
    "            # check if the bucket has same key as\n",
    "            # the key to be inserted\n",
    "            if record_key == key:\n",
    "                found_key = True\n",
    "                break\n",
    " \n",
    "        # If the bucket has same key as the key to be inserted,\n",
    "        # Update the key value\n",
    "        # Otherwise append the new key-value pair to the bucket\n",
    "        if found_key:\n",
    "            bucket[index] = (key, val)\n",
    "        else:\n",
    "            bucket.append((key, val))\n",
    " \n",
    "    # Return searched value with specific key\n",
    "    def get_val(self, key):\n",
    "       \n",
    "        # Get the index from the key using\n",
    "        # hash function\n",
    "        hashed_key = hash(key) % self.size\n",
    "         \n",
    "        # Get the bucket corresponding to index\n",
    "        bucket = self.hash_table[hashed_key]\n",
    " \n",
    "        found_key = False\n",
    "        for index, record in enumerate(bucket):\n",
    "            record_key, record_val = record\n",
    "             \n",
    "            # check if the bucket has same key as\n",
    "            # the key being searched\n",
    "            if record_key == key:\n",
    "                found_key = True\n",
    "                break\n",
    " \n",
    "        # If the bucket has same key as the key being searched,\n",
    "        # Return the value found\n",
    "        # Otherwise indicate there was no record found\n",
    "        if found_key:\n",
    "            return record_val\n",
    "        else:\n",
    "            return \"No record found\"\n",
    " \n",
    "    # Remove a value with specific key\n",
    "    def delete_val(self, key):\n",
    "       \n",
    "        # Get the index from the key using\n",
    "        # hash function\n",
    "        hashed_key = hash(key) % self.size\n",
    "         \n",
    "        # Get the bucket corresponding to index\n",
    "        bucket = self.hash_table[hashed_key]\n",
    " \n",
    "        found_key = False\n",
    "        for index, record in enumerate(bucket):\n",
    "            record_key, record_val = record\n",
    "             \n",
    "            # check if the bucket has same key as\n",
    "            # the key to be deleted\n",
    "            if record_key == key:\n",
    "                found_key = True\n",
    "                break\n",
    "        if found_key:\n",
    "            bucket.pop(index)\n",
    "        return\n",
    " \n",
    "    # To print the items of hash map\n",
    "    def __str__(self):\n",
    "        return \"\".join(str(item) for item in self.hash_table)\n",
    " \n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/content/gdrive/My Drive/FYP Sample Data/Sample-Data-updated.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m data \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(\u001b[39m'\u001b[39;49m\u001b[39m/content/gdrive/My Drive/FYP Sample Data/Sample-Data-updated.csv\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m      2\u001b[0m required_data \u001b[39m=\u001b[39m data[[\u001b[39m\"\u001b[39m\u001b[39mPhi_1\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39mPhi\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39mPhi_2\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39mX\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39mY\u001b[39m\u001b[39m\"\u001b[39m]]\n\u001b[0;32m      3\u001b[0m \u001b[39mlen\u001b[39m(required_data)\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    899\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    900\u001b[0m     dialect,\n\u001b[0;32m    901\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    908\u001b[0m     dtype_backend\u001b[39m=\u001b[39mdtype_backend,\n\u001b[0;32m    909\u001b[0m )\n\u001b[0;32m    910\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 912\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    574\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[0;32m    576\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 577\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[0;32m    579\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[0;32m    580\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1404\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m   1406\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1407\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1661\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1659\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode:\n\u001b[0;32m   1660\u001b[0m         mode \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m-> 1661\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(\n\u001b[0;32m   1662\u001b[0m     f,\n\u001b[0;32m   1663\u001b[0m     mode,\n\u001b[0;32m   1664\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1665\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1666\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[0;32m   1667\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[0;32m   1668\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m   1669\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1670\u001b[0m )\n\u001b[0;32m   1671\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1672\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\pandas\\io\\common.py:859\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    854\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[0;32m    855\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    856\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    857\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[0;32m    858\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[1;32m--> 859\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[0;32m    860\u001b[0m             handle,\n\u001b[0;32m    861\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[0;32m    862\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[0;32m    863\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[0;32m    864\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    865\u001b[0m         )\n\u001b[0;32m    866\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    867\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[0;32m    868\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/gdrive/My Drive/FYP Sample Data/Sample-Data-updated.csv'"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('/content/gdrive/My Drive/FYP Sample Data/Sample-Data-updated.csv')\n",
    "required_data = data[[\"Phi_1\",\"Phi\",\"Phi_2\",\"X\",\"Y\"]]\n",
    "len(required_data)\n",
    "hash_table = HashTable(22650)\n",
    "\n",
    "#temporarily storing all 5 values in one 3 D matrix named temp_all_data_storage\n",
    "temp_all_data_storage = np.empty((len(required_data),5))\n",
    "count = 0\n",
    "for ind in required_data.index:\n",
    "  temp_all_data_storage[ind][0] = required_data['Phi_1'][ind]\n",
    "  temp_all_data_storage[ind][1] = required_data['Phi'][ind]\n",
    "  temp_all_data_storage[ind][2] = required_data['Phi_2'][ind]\n",
    "  temp_all_data_storage[ind][3] = required_data['X'][ind]\n",
    "  temp_all_data_storage[ind][4] = required_data['Y'][ind]\n",
    "  left = str(required_data['X'][ind]) + str(required_data['Y'][ind])\n",
    "  right = str(count)\n",
    "  count = count + 1\n",
    "  hash_table.set_val('left', 'right')\n",
    "\n",
    "\n",
    "# Store the euler angles in euler_angle_mat\n",
    "euler_angle_mat = np.empty((len(required_data),3))\n",
    "\n",
    "for ind in required_data.index:\n",
    "  euler_angle_mat[ind][0] = required_data['Phi_1'][ind]\n",
    "  euler_angle_mat[ind][1] = required_data['Phi'][ind]\n",
    "  euler_angle_mat[ind][2] = required_data['Phi_2'][ind]\n",
    "euler_angle_mat\n",
    "\n",
    "# s_i values assigned in the array si_j_values_mat \n",
    "si_j_values_mat = np.empty((len(required_data),3))\n",
    "for ind in required_data.index:\n",
    "\n",
    "  current_s_i = np.random.randint(0, 429)\n",
    "  si_j_values_mat[ind][0] = required_data['X'][ind]\n",
    "  si_j_values_mat[ind][1] = required_data['Y'][ind]\n",
    "  si_j_values_mat[ind][2] = current_s_i\n",
    "\n",
    "# get the 24 values of rotation_point_groups\n",
    "rotation_mat = rotation_point_groups()\n",
    "\n",
    "# 3 D matrix for storing the updated euler angles\n",
    "updated_rotation_mat = np.empty((len(required_data),24,3))\n",
    "\n",
    "for i in range(len(euler_angle_mat)):\n",
    "\n",
    "  # Multiplying each euler_angle_mat entry with 24 rotation matrices\n",
    "  for j in range(0,len(rotation_mat)):\n",
    "    updated_rotation_mat[i][j][0] = np.dot(euler_angle_mat[i],rotation_mat[j])[0]\n",
    "    updated_rotation_mat[i][j][1] = np.dot(euler_angle_mat[i],rotation_mat[j])[1]\n",
    "    updated_rotation_mat[i][j][2] = np.dot(euler_angle_mat[i],rotation_mat[j])[2]\n",
    "\n",
    "\n",
    "x = random_point_x()\n",
    "y = random_point_y()\n",
    "\n",
    "\n",
    "\n",
    "ans_arr = np.empty(4)\n",
    "neighbours = neighbours_of_point(x,y)\n",
    "for j in range(0, len(neighbours)):\n",
    "\n",
    "  first_set = current_euler_angle(required_data, x, y)\n",
    "  j_x = neighbours[j][0]\n",
    "  j_y = neighbours[j][1]\n",
    "  \n",
    "  res = 360.\n",
    "\n",
    "  search_key = str(j_x) + str(j_y)\n",
    "  index = hash_table.get_val('search_key')\n",
    "\n",
    "  for l in range(len(updated_rotation_mat[index])):\n",
    "    second_set = [updated_rotation_mat[index][l][0],updated_rotation_mat[index][l][0],updated_rotation_mat[index][l][0]]\n",
    "    t = theta_calculator(first_set, second_set)\n",
    "    res = np.minimum(res,t)\n",
    "    \n",
    "\n",
    "    # for m in range(len(updated_rotation_mat[l])):\n",
    "    #   if( updated_rotation_mat[l][m]):\n",
    "        \n",
    "    # if( updated_rotation_mat[l][])\n",
    "    # second_set = updated_rotation_mat[l]\n",
    "    # t = theta_calculator(first_set, second_set[l])\n",
    "\n",
    "    # if( t.all() < res):\n",
    "    #   res = t\n",
    "  ans_arr[j] = res\n",
    "ans_arr\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
